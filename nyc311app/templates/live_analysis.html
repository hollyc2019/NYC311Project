<h2>Live 311 Data</h2>

<br>

<b>There's between 4,000 and 10,000 complaints per day. Depending whether it's the day after New Years or it's a random Wednesday. </b>

<br>
<br>

<b>This was a quick addition to the project and probably made the project more fun.</b>

<h3>How Was This Made</h3>

<ul>
	<p>A quick API call to 311, idicating the desired date range and 5 seconds of our time depending on the range, returned 311 complaints. R has a function <i>read.csv()</i> that doubles as a request module and you could pass urls in and make http requests. </p>
</ul>

<ul>
	<p>Single line of code got us our data in real time. The rest of the logic is what we used to clean and plot data, except in the live portion the data is being cleaned everytime you change the date range or choose a new complaint.</p>
</ul>


<h3>Issues To Address:</h3>

<br>

<ul>
	<p>We're using the top 15 most complaints from February. Depending on your date range and the complaint or complaints you select, some might not show up. We'd like to get the top 15 complaints from the range you select. We decided not to work on that and focus on the analysis of February 2018.</p>
</ul>

<ul>
	<p>The image of NYC is in between zooms if we zoom once more out it's too much space. If we zoom in once more, we're cutting out much of NYC. Some outskirts of NYC still get cut out and some data points are not included. Would be great to display how much data is lost when plotting.</p>
</ul>

<ul>
	<p>Some complaints don't have location and are not plotted. Would also be great to let the user know how much data is being lost to that. In our experience with 311 data there's almost always a location included with complaint.</p>
</ul>

<h3>Code:</h3>
<p>
	Click <a target="_blank" href="https://github.com/odubno/NYC311Project/blob/master/live_311.Rmd">here</a> to view the code on GitHub.
</p>